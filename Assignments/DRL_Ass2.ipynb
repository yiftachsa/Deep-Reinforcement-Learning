{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DRL_Ass2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOOLUVuEOnII",
        "outputId": "995ad7aa-a6b6-4b82-bc1a-b46d085fd2fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 16.7 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 51 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 61 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 71 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 92 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 102 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 112 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 122 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 124 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.4.1\n",
            "Collecting tf_slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "!pip install tensorboardX\n",
        "\n",
        "!pip install tf_slim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import collections\n",
        "import datetime\n",
        "import tf_slim as slim\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline               \n"
      ],
      "metadata": {
        "id": "HN1kCRH_PBv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actor-Critic"
      ],
      "metadata": {
        "id": "49JqRgsBbPvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PolicyNetwork:\n",
        "    def __init__(self, state_size, action_size, learning_rate, name='policy_network'):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        with tf.variable_scope(name):\n",
        "            global_step = tf.Variable(0, trainable=False)\n",
        "\n",
        "            learning_rate = tf.train.exponential_decay(self.learning_rate, global_step,\n",
        "                                       1000, 0.95, staircase=True)\n",
        "            \n",
        "            self.state = tf.placeholder(tf.float32, [None, self.state_size], name=\"state\")\n",
        "            self.action = tf.placeholder(tf.int32, [self.action_size], name=\"action\")\n",
        "            self.R_t = tf.placeholder(tf.float32, name=\"total_rewards\")\n",
        "\n",
        "            self.W1 = tf.get_variable(\"W1\", [self.state_size, 12], initializer=tf.keras.initializers.glorot_normal(seed=0))\n",
        "            self.b1 = tf.get_variable(\"b1\", [12], initializer=tf.zeros_initializer())\n",
        "            self.W2 = tf.get_variable(\"W2\", [12, self.action_size], initializer=tf.keras.initializers.glorot_normal(seed=0))\n",
        "            self.b2 = tf.get_variable(\"b2\", [self.action_size], initializer=tf.zeros_initializer())\n",
        "\n",
        "            self.Z1 = tf.add(tf.matmul(self.state, self.W1), self.b1)\n",
        "            self.A1 = tf.nn.relu(self.Z1)\n",
        "            self.output = tf.add(tf.matmul(self.A1, self.W2), self.b2)\n",
        "\n",
        "            # Softmax probability distribution over actions\n",
        "            self.actions_distribution = tf.squeeze(tf.nn.softmax(self.output)) \n",
        "            # Loss with negative log probability\n",
        "            self.neg_log_prob = tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.output, labels=self.action)\n",
        "            self.loss = tf.reduce_mean(self.neg_log_prob * self.R_t)\n",
        "            self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.loss, global_step=global_step)"
      ],
      "metadata": {
        "id": "KorKl1ENGnwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ValueEstimator():\n",
        "    \n",
        "    def __init__(self, state_size, action_size, learning_rate, name='value_network'):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size \n",
        "        self.learning_rate = learning_rate\n",
        "        \n",
        "        self.n_outputs = 1\n",
        "        # Define number of hidden nodes\n",
        "        self.n_hidden_nodes = 16\n",
        "        \n",
        "        with tf.variable_scope(name):\n",
        "            global_step = tf.Variable(0, trainable=False)\n",
        "\n",
        "            learning_rate = tf.train.exponential_decay(self.learning_rate, global_step,\n",
        "                                       1000, 0.98, staircase=True)\n",
        "            \n",
        "            self.state = tf.placeholder(tf.float32, [None, self.state_size], name=\"state\")\n",
        "            self.action = tf.placeholder(tf.int32, [self.action_size], name=\"action\") \n",
        "            self.R_t = tf.placeholder(tf.float32, name=\"total_rewards\")\n",
        "\n",
        "            initializer = tf.keras.initializers.glorot_normal(seed=0)\n",
        "\n",
        "            layer_1 = slim.fully_connected(self.state, self.n_hidden_nodes, activation_fn=tf.nn.relu, weights_initializer=initializer)\n",
        "            output_layer = slim.fully_connected(layer_1, self.n_outputs, activation_fn=None, weights_initializer=initializer)\n",
        "            \n",
        "            self.state_value_estimation = tf.squeeze(output_layer)\n",
        "    \n",
        "            # Define loss function as squared difference between estimate and actual\n",
        "            self.loss = tf.reduce_mean(tf.squared_difference(self.state_value_estimation, self.R_t))\n",
        "            self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.loss, global_step=global_step)"
      ],
      "metadata": {
        "id": "Ym1fCOQgD3xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "np.random.seed(1)\n",
        "writer = SummaryWriter()\n",
        "# Define hyperparameters\n",
        "state_size = 4\n",
        "action_size = env.action_space.n\n",
        "\n",
        "max_episodes = 5000\n",
        "max_steps = 501\n",
        "discount_factor = 0.99\n",
        "learning_rate_value = 0.01\n",
        "learning_rate_policy = 0.001\n",
        "render = False\n",
        "\n",
        "# Initialize the policy network\n",
        "tf.reset_default_graph()\n",
        "policy = PolicyNetwork(state_size, action_size, learning_rate_policy)\n",
        "value = ValueEstimator(state_size, action_size, learning_rate_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_1qfPwybcBt",
        "outputId": "c2276f91-943e-4b34-be06-b087e08e89b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training the agent with REINFORCE algorithm\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    solved = False\n",
        "    Transition = collections.namedtuple(\"Transition\", [\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "    episode_rewards = np.zeros(max_episodes)\n",
        "    average_rewards = 0.0\n",
        "    for episode in range(max_episodes):\n",
        "        state = env.reset()\n",
        "        state = state.reshape([1, state_size])\n",
        "        I = 1\n",
        "        episode_transitions = []\n",
        "        episode_val_losses = []\n",
        "        episode_policy_losses = []\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            actions_distribution = sess.run(policy.actions_distribution, {policy.state: state})\n",
        "            action = np.random.choice(np.arange(len(actions_distribution)), p=actions_distribution)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            next_state = next_state.reshape([1, state_size])\n",
        "\n",
        "            if render:\n",
        "                env.render()\n",
        "\n",
        "            action_one_hot = np.zeros(action_size)\n",
        "            action_one_hot[action] = 1\n",
        "            \n",
        "            episode_transitions.append(Transition(state=state, action=action_one_hot, reward=reward, next_state=next_state, done=done))\n",
        "            episode_rewards[episode] += reward\n",
        "\n",
        "            # Compute value estimations\n",
        "            estimated_return_state = sess.run([value.state_value_estimation], {value.state: state})[0]\n",
        "            if not done:\n",
        "              estimated_return_next_state = sess.run([value.state_value_estimation], {value.state: next_state})[0]\n",
        "              discounted_estimated_return_next_state = discount_factor * estimated_return_next_state\n",
        "            else:\n",
        "              discounted_estimated_return_next_state = 0\n",
        "            # Compute TD-error \n",
        "            delta = (reward + discounted_estimated_return_next_state) - estimated_return_state\n",
        "            delta_I = I * delta\n",
        "            \n",
        "\n",
        "            # Value function update\n",
        "            value_feed_dict= {value.state: state, value.R_t: reward + discounted_estimated_return_next_state} \n",
        "            _, val_loss = sess.run([value.optimizer, value.loss], value_feed_dict)\n",
        "            episode_val_losses.append(val_loss)\n",
        "            # Policy function update\n",
        "            feed_dict = {policy.state: state, policy.R_t: delta_I, policy.action: action_one_hot} \n",
        "            _, policy_loss = sess.run([policy.optimizer, policy.loss], feed_dict)\n",
        "            episode_policy_losses.append(policy_loss)\n",
        "\n",
        "            if done:\n",
        "                if episode > 98:\n",
        "                    # Check if solved\n",
        "                    average_rewards = np.mean(episode_rewards[(episode - 99):episode+1])\n",
        "                print(\"Episode {} Reward: {} Average over 100 episodes: {}\".format(episode, episode_rewards[episode], round(average_rewards, 2)))\n",
        "                print(f\"Mean Value Loss: {np.mean(episode_val_losses)}, Mean Policy Loss: {np.mean(episode_policy_losses)}\")\n",
        "                if average_rewards > 475:\n",
        "                    print(' Solved at episode: ' + str(episode))\n",
        "                    solved = True\n",
        "                break\n",
        "            state = next_state\n",
        "            I = discount_factor * I\n",
        "        writer.add_scalar('Total Reward', episode_rewards[episode], episode)\n",
        "        writer.add_scalar('Steps', step, episode)\n",
        "\n",
        "        if solved:\n",
        "            break\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "    plt.plot(range(episode),episode_rewards[:episode])\n",
        "    plt.xlabel('Eposode')\n",
        "    plt.ylabel('Rewards')\n",
        "    plt.title('The total rewared')\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "16Gj5pGfbSeM",
        "outputId": "5f2cad7d-49f7-4bc4-9000-6451871073cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0 Reward: 11.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 0.985829770565033, Mean Policy Loss: 0.588636040687561\n",
            "Episode 1 Reward: 66.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 1.1857959032058716, Mean Policy Loss: 0.4530952274799347\n",
            "Episode 2 Reward: 14.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 17.20844268798828, Mean Policy Loss: 0.16825342178344727\n",
            "Episode 3 Reward: 25.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 9.04701042175293, Mean Policy Loss: 0.34330862760543823\n",
            "Episode 4 Reward: 20.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 9.078557014465332, Mean Policy Loss: 0.2149103879928589\n",
            "Episode 5 Reward: 46.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 6.525184154510498, Mean Policy Loss: 0.19886381924152374\n",
            "Episode 6 Reward: 20.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 9.367822647094727, Mean Policy Loss: 0.3008207082748413\n",
            "Episode 7 Reward: 9.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 19.985401153564453, Mean Policy Loss: 0.03462650999426842\n",
            "Episode 8 Reward: 33.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 4.524799823760986, Mean Policy Loss: 0.03162745386362076\n",
            "Episode 9 Reward: 13.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 9.504966735839844, Mean Policy Loss: 0.1622721403837204\n",
            "Episode 10 Reward: 11.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 6.506709575653076, Mean Policy Loss: 0.027631185948848724\n",
            "Episode 11 Reward: 16.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 21.593164443969727, Mean Policy Loss: -0.15817397832870483\n",
            "Episode 12 Reward: 13.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 2.948380470275879, Mean Policy Loss: 0.08022023737430573\n",
            "Episode 13 Reward: 21.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 5.771982669830322, Mean Policy Loss: 0.23959945142269135\n",
            "Episode 14 Reward: 24.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 3.470165252685547, Mean Policy Loss: 0.3583994209766388\n",
            "Episode 15 Reward: 10.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 4.8878374099731445, Mean Policy Loss: -0.04272265359759331\n",
            "Episode 16 Reward: 36.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 6.955810546875, Mean Policy Loss: 0.39483872056007385\n",
            "Episode 17 Reward: 30.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 3.1097772121429443, Mean Policy Loss: 0.3691745400428772\n",
            "Episode 18 Reward: 14.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 61.582496643066406, Mean Policy Loss: -0.08203274756669998\n",
            "Episode 19 Reward: 37.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 8.517254829406738, Mean Policy Loss: 0.26182252168655396\n",
            "Episode 20 Reward: 13.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 43.64928436279297, Mean Policy Loss: -0.6347854137420654\n",
            "Episode 21 Reward: 30.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 17.152833938598633, Mean Policy Loss: 0.24638631939888\n",
            "Episode 22 Reward: 17.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 20.341825485229492, Mean Policy Loss: 0.016393212601542473\n",
            "Episode 23 Reward: 31.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 9.633733749389648, Mean Policy Loss: 0.2527236342430115\n",
            "Episode 24 Reward: 30.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 14.938902854919434, Mean Policy Loss: 0.2275749146938324\n",
            "Episode 25 Reward: 13.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 23.65934944152832, Mean Policy Loss: -0.2536364793777466\n",
            "Episode 26 Reward: 55.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 7.2861714363098145, Mean Policy Loss: 0.2924709618091583\n",
            "Episode 27 Reward: 16.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 29.188154220581055, Mean Policy Loss: -0.342260479927063\n",
            "Episode 28 Reward: 13.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 34.09823989868164, Mean Policy Loss: -0.5178117752075195\n",
            "Episode 29 Reward: 22.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 12.687111854553223, Mean Policy Loss: 0.057322677224874496\n",
            "Episode 30 Reward: 40.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 10.89633560180664, Mean Policy Loss: 0.2917591333389282\n",
            "Episode 31 Reward: 31.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 12.484935760498047, Mean Policy Loss: 0.08427158743143082\n",
            "Episode 32 Reward: 28.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 13.648785591125488, Mean Policy Loss: 0.00048167366185225546\n",
            "Episode 33 Reward: 15.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 22.314334869384766, Mean Policy Loss: -0.17842045426368713\n",
            "Episode 34 Reward: 20.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 14.378753662109375, Mean Policy Loss: -0.12880472838878632\n",
            "Episode 35 Reward: 22.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 16.314849853515625, Mean Policy Loss: -0.13206495344638824\n",
            "Episode 36 Reward: 39.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 4.350571155548096, Mean Policy Loss: 0.25693902373313904\n",
            "Episode 37 Reward: 47.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 3.7807695865631104, Mean Policy Loss: 0.21921883523464203\n",
            "Episode 38 Reward: 39.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 17.74416160583496, Mean Policy Loss: 0.18578723073005676\n",
            "Episode 39 Reward: 55.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 4.245904445648193, Mean Policy Loss: 0.2795538902282715\n",
            "Episode 40 Reward: 14.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 54.20061492919922, Mean Policy Loss: -0.21242816746234894\n",
            "Episode 41 Reward: 17.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 29.617168426513672, Mean Policy Loss: -0.12528441846370697\n",
            "Episode 42 Reward: 15.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 29.934770584106445, Mean Policy Loss: -0.2927270829677582\n",
            "Episode 43 Reward: 14.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 25.63882064819336, Mean Policy Loss: -0.36679935455322266\n",
            "Episode 44 Reward: 14.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 22.49619483947754, Mean Policy Loss: -0.4079352915287018\n",
            "Episode 45 Reward: 20.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 20.995532989501953, Mean Policy Loss: 0.08251290023326874\n",
            "Episode 46 Reward: 18.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 14.298526763916016, Mean Policy Loss: -0.06914106756448746\n",
            "Episode 47 Reward: 28.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 13.615407943725586, Mean Policy Loss: 0.2050658017396927\n",
            "Episode 48 Reward: 21.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 9.26029109954834, Mean Policy Loss: 0.0445571169257164\n",
            "Episode 49 Reward: 24.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 16.462331771850586, Mean Policy Loss: 0.19187770783901215\n",
            "Episode 50 Reward: 15.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 25.066814422607422, Mean Policy Loss: -0.04088045656681061\n",
            "Episode 51 Reward: 24.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 13.51941204071045, Mean Policy Loss: -0.00749121094122529\n",
            "Episode 52 Reward: 20.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 14.271703720092773, Mean Policy Loss: -0.1347726285457611\n",
            "Episode 53 Reward: 11.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 16.456464767456055, Mean Policy Loss: -0.3940272331237793\n",
            "Episode 54 Reward: 58.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 3.576404333114624, Mean Policy Loss: 0.27812254428863525\n",
            "Episode 55 Reward: 11.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 16.92736053466797, Mean Policy Loss: -0.7238206267356873\n",
            "Episode 56 Reward: 26.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 11.734918594360352, Mean Policy Loss: -0.047582004219293594\n",
            "Episode 57 Reward: 13.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 11.677316665649414, Mean Policy Loss: -0.29256102442741394\n",
            "Episode 58 Reward: 21.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 12.956140518188477, Mean Policy Loss: 0.15183909237384796\n",
            "Episode 59 Reward: 20.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 10.155546188354492, Mean Policy Loss: 0.020667051896452904\n",
            "Episode 60 Reward: 10.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 23.409006118774414, Mean Policy Loss: -0.3771992325782776\n",
            "Episode 61 Reward: 17.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 11.075676918029785, Mean Policy Loss: -0.25411567091941833\n",
            "Episode 62 Reward: 66.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 3.2355258464813232, Mean Policy Loss: 0.3090178668498993\n",
            "Episode 63 Reward: 21.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 13.822643280029297, Mean Policy Loss: 0.08998905122280121\n",
            "Episode 64 Reward: 28.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 9.415288925170898, Mean Policy Loss: 0.1918303668498993\n",
            "Episode 65 Reward: 22.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 11.566749572753906, Mean Policy Loss: 0.06075657531619072\n",
            "Episode 66 Reward: 29.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 5.8739914894104, Mean Policy Loss: 0.12104945629835129\n",
            "Episode 67 Reward: 18.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 10.462860107421875, Mean Policy Loss: -0.0920865535736084\n",
            "Episode 68 Reward: 17.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 4.221374988555908, Mean Policy Loss: -0.1464616358280182\n",
            "Episode 69 Reward: 25.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 6.561387538909912, Mean Policy Loss: -0.155911386013031\n",
            "Episode 70 Reward: 53.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 5.326984882354736, Mean Policy Loss: 0.20597928762435913\n",
            "Episode 71 Reward: 14.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 28.00782585144043, Mean Policy Loss: -0.7611932158470154\n",
            "Episode 72 Reward: 14.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 11.458914756774902, Mean Policy Loss: -0.49703794717788696\n",
            "Episode 73 Reward: 13.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 3.616687536239624, Mean Policy Loss: -0.5229813456535339\n",
            "Episode 74 Reward: 49.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 4.062404632568359, Mean Policy Loss: 0.15152327716350555\n",
            "Episode 75 Reward: 21.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 20.06893539428711, Mean Policy Loss: 0.07971681654453278\n",
            "Episode 76 Reward: 32.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 9.655800819396973, Mean Policy Loss: -0.28621089458465576\n",
            "Episode 77 Reward: 17.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 16.248220443725586, Mean Policy Loss: -0.4456193447113037\n",
            "Episode 78 Reward: 64.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 4.789361953735352, Mean Policy Loss: 0.1768951565027237\n",
            "Episode 79 Reward: 41.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 9.759057998657227, Mean Policy Loss: 0.03595747426152229\n",
            "Episode 80 Reward: 46.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 4.850495338439941, Mean Policy Loss: -0.0048198699951171875\n",
            "Episode 81 Reward: 20.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 19.749649047851562, Mean Policy Loss: -0.20663490891456604\n",
            "Episode 82 Reward: 95.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 24.02297019958496, Mean Policy Loss: 0.1791502684354782\n",
            "Episode 83 Reward: 77.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 21.913541793823242, Mean Policy Loss: -0.09787748008966446\n",
            "Episode 84 Reward: 29.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 35.63066101074219, Mean Policy Loss: -0.744676411151886\n",
            "Episode 85 Reward: 112.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 3.511732816696167, Mean Policy Loss: 0.05341766029596329\n",
            "Episode 86 Reward: 80.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 16.111248016357422, Mean Policy Loss: 0.1335488259792328\n",
            "Episode 87 Reward: 166.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 9.34126091003418, Mean Policy Loss: 0.06339117139577866\n",
            "Episode 88 Reward: 68.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 17.15691375732422, Mean Policy Loss: -0.04744643345475197\n",
            "Episode 89 Reward: 47.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 35.0118522644043, Mean Policy Loss: -0.418235182762146\n",
            "Episode 90 Reward: 56.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 31.324934005737305, Mean Policy Loss: 0.21313108503818512\n",
            "Episode 91 Reward: 122.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 7.916540622711182, Mean Policy Loss: 0.09515543282032013\n",
            "Episode 92 Reward: 93.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 17.272951126098633, Mean Policy Loss: 0.07017206400632858\n",
            "Episode 93 Reward: 140.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 2.189408779144287, Mean Policy Loss: 0.05933593213558197\n",
            "Episode 94 Reward: 44.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 80.63106536865234, Mean Policy Loss: 0.15190653502941132\n",
            "Episode 95 Reward: 68.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 50.9021110534668, Mean Policy Loss: 0.16887468099594116\n",
            "Episode 96 Reward: 44.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 30.681394577026367, Mean Policy Loss: -0.22056278586387634\n",
            "Episode 97 Reward: 27.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 59.155738830566406, Mean Policy Loss: 0.08169020712375641\n",
            "Episode 98 Reward: 24.0 Average over 100 episodes: 0.0\n",
            "Mean Value Loss: 42.08660888671875, Mean Policy Loss: -0.25997689366340637\n",
            "Episode 99 Reward: 112.0 Average over 100 episodes: 34.9\n",
            "Mean Value Loss: 9.582087516784668, Mean Policy Loss: 0.07646101713180542\n",
            "Episode 100 Reward: 113.0 Average over 100 episodes: 35.92\n",
            "Mean Value Loss: 25.049419403076172, Mean Policy Loss: 0.12457269430160522\n",
            "Episode 101 Reward: 101.0 Average over 100 episodes: 36.27\n",
            "Mean Value Loss: 15.54465103149414, Mean Policy Loss: 0.09102354198694229\n",
            "Episode 102 Reward: 66.0 Average over 100 episodes: 36.79\n",
            "Mean Value Loss: 21.374534606933594, Mean Policy Loss: 0.02217922732234001\n",
            "Episode 103 Reward: 40.0 Average over 100 episodes: 36.94\n",
            "Mean Value Loss: 38.3028564453125, Mean Policy Loss: -0.09533192962408066\n",
            "Episode 104 Reward: 30.0 Average over 100 episodes: 37.04\n",
            "Mean Value Loss: 52.114627838134766, Mean Policy Loss: 0.05943441390991211\n",
            "Episode 105 Reward: 14.0 Average over 100 episodes: 36.72\n",
            "Mean Value Loss: 71.4014892578125, Mean Policy Loss: -0.6220270395278931\n",
            "Episode 106 Reward: 45.0 Average over 100 episodes: 36.97\n",
            "Mean Value Loss: 22.80049705505371, Mean Policy Loss: -0.45624950528144836\n",
            "Episode 107 Reward: 99.0 Average over 100 episodes: 37.87\n",
            "Mean Value Loss: 4.523601531982422, Mean Policy Loss: 0.08618056774139404\n",
            "Episode 108 Reward: 55.0 Average over 100 episodes: 38.09\n",
            "Mean Value Loss: 12.403440475463867, Mean Policy Loss: -0.027419237419962883\n",
            "Episode 109 Reward: 82.0 Average over 100 episodes: 38.78\n",
            "Mean Value Loss: 28.122112274169922, Mean Policy Loss: 0.12020782381296158\n",
            "Episode 110 Reward: 59.0 Average over 100 episodes: 39.26\n",
            "Mean Value Loss: 39.861576080322266, Mean Policy Loss: 0.006335743237286806\n",
            "Episode 111 Reward: 42.0 Average over 100 episodes: 39.52\n",
            "Mean Value Loss: 40.15248107910156, Mean Policy Loss: 0.14298611879348755\n",
            "Episode 112 Reward: 84.0 Average over 100 episodes: 40.23\n",
            "Mean Value Loss: 5.293088436126709, Mean Policy Loss: -0.1817467361688614\n",
            "Episode 113 Reward: 29.0 Average over 100 episodes: 40.31\n",
            "Mean Value Loss: 39.7576789855957, Mean Policy Loss: -0.07681022584438324\n",
            "Episode 114 Reward: 48.0 Average over 100 episodes: 40.55\n",
            "Mean Value Loss: 31.4385986328125, Mean Policy Loss: -0.15518499910831451\n",
            "Episode 115 Reward: 29.0 Average over 100 episodes: 40.74\n",
            "Mean Value Loss: 36.730098724365234, Mean Policy Loss: -0.40272387862205505\n",
            "Episode 116 Reward: 23.0 Average over 100 episodes: 40.61\n",
            "Mean Value Loss: 35.37617874145508, Mean Policy Loss: -0.37341955304145813\n",
            "Episode 117 Reward: 88.0 Average over 100 episodes: 41.19\n",
            "Mean Value Loss: 17.619861602783203, Mean Policy Loss: 0.02376222424209118\n",
            "Episode 118 Reward: 62.0 Average over 100 episodes: 41.67\n",
            "Mean Value Loss: 12.79206371307373, Mean Policy Loss: 0.0735800713300705\n",
            "Episode 119 Reward: 114.0 Average over 100 episodes: 42.44\n",
            "Mean Value Loss: 27.225122451782227, Mean Policy Loss: 0.190596804022789\n",
            "Episode 120 Reward: 78.0 Average over 100 episodes: 43.09\n",
            "Mean Value Loss: 19.30171012878418, Mean Policy Loss: 0.10666117072105408\n",
            "Episode 121 Reward: 108.0 Average over 100 episodes: 43.87\n",
            "Mean Value Loss: 18.15325164794922, Mean Policy Loss: 0.04760187119245529\n",
            "Episode 122 Reward: 43.0 Average over 100 episodes: 44.13\n",
            "Mean Value Loss: 25.07560157775879, Mean Policy Loss: -0.014233672060072422\n",
            "Episode 123 Reward: 43.0 Average over 100 episodes: 44.25\n",
            "Mean Value Loss: 28.186588287353516, Mean Policy Loss: -0.1548995077610016\n",
            "Episode 124 Reward: 128.0 Average over 100 episodes: 45.23\n",
            "Mean Value Loss: 7.446289539337158, Mean Policy Loss: 0.05022751912474632\n",
            "Episode 125 Reward: 96.0 Average over 100 episodes: 46.06\n",
            "Mean Value Loss: 28.25035285949707, Mean Policy Loss: 0.057456862181425095\n",
            "Episode 126 Reward: 89.0 Average over 100 episodes: 46.4\n",
            "Mean Value Loss: 10.36942195892334, Mean Policy Loss: 0.08983353525400162\n",
            "Episode 127 Reward: 64.0 Average over 100 episodes: 46.88\n",
            "Mean Value Loss: 16.158397674560547, Mean Policy Loss: -0.1991819143295288\n",
            "Episode 128 Reward: 69.0 Average over 100 episodes: 47.44\n",
            "Mean Value Loss: 14.817924499511719, Mean Policy Loss: 0.05948713421821594\n",
            "Episode 129 Reward: 40.0 Average over 100 episodes: 47.62\n",
            "Mean Value Loss: 25.475427627563477, Mean Policy Loss: -0.952872097492218\n",
            "Episode 130 Reward: 48.0 Average over 100 episodes: 47.7\n",
            "Mean Value Loss: 5.669218063354492, Mean Policy Loss: 0.02759481966495514\n",
            "Episode 131 Reward: 72.0 Average over 100 episodes: 48.11\n",
            "Mean Value Loss: 2.016206979751587, Mean Policy Loss: 0.06525790691375732\n",
            "Episode 132 Reward: 78.0 Average over 100 episodes: 48.61\n",
            "Mean Value Loss: 4.650884628295898, Mean Policy Loss: 0.02862677164375782\n",
            "Episode 133 Reward: 97.0 Average over 100 episodes: 49.43\n",
            "Mean Value Loss: 47.46487045288086, Mean Policy Loss: -0.019093267619609833\n",
            "Episode 134 Reward: 107.0 Average over 100 episodes: 50.3\n",
            "Mean Value Loss: 5.2027997970581055, Mean Policy Loss: 0.052408620715141296\n",
            "Episode 135 Reward: 121.0 Average over 100 episodes: 51.29\n",
            "Mean Value Loss: 4.344356536865234, Mean Policy Loss: 0.04782118648290634\n",
            "Episode 136 Reward: 36.0 Average over 100 episodes: 51.26\n",
            "Mean Value Loss: 60.28532028198242, Mean Policy Loss: -1.72246253490448\n",
            "Episode 137 Reward: 111.0 Average over 100 episodes: 51.9\n",
            "Mean Value Loss: 30.46892547607422, Mean Policy Loss: 0.07399041205644608\n",
            "Episode 138 Reward: 70.0 Average over 100 episodes: 52.21\n",
            "Mean Value Loss: 15.449705123901367, Mean Policy Loss: -0.6368021965026855\n",
            "Episode 139 Reward: 69.0 Average over 100 episodes: 52.35\n",
            "Mean Value Loss: 29.436344146728516, Mean Policy Loss: -0.025692850351333618\n",
            "Episode 140 Reward: 172.0 Average over 100 episodes: 53.93\n",
            "Mean Value Loss: 3.5693743228912354, Mean Policy Loss: 0.05259551480412483\n",
            "Episode 141 Reward: 139.0 Average over 100 episodes: 55.15\n",
            "Mean Value Loss: 22.54214859008789, Mean Policy Loss: 0.03715869039297104\n",
            "Episode 142 Reward: 73.0 Average over 100 episodes: 55.73\n",
            "Mean Value Loss: 36.14888000488281, Mean Policy Loss: -0.13341942429542542\n",
            "Episode 143 Reward: 138.0 Average over 100 episodes: 56.97\n",
            "Mean Value Loss: 18.75568199157715, Mean Policy Loss: 0.057118721306324005\n",
            "Episode 144 Reward: 99.0 Average over 100 episodes: 57.82\n",
            "Mean Value Loss: 16.64254379272461, Mean Policy Loss: -0.07186540961265564\n",
            "Episode 145 Reward: 116.0 Average over 100 episodes: 58.78\n",
            "Mean Value Loss: 14.051029205322266, Mean Policy Loss: 0.06439948827028275\n",
            "Episode 146 Reward: 189.0 Average over 100 episodes: 60.49\n",
            "Mean Value Loss: 32.46258544921875, Mean Policy Loss: 0.029407093301415443\n",
            "Episode 147 Reward: 103.0 Average over 100 episodes: 61.24\n",
            "Mean Value Loss: 22.112327575683594, Mean Policy Loss: 0.06004772707819939\n",
            "Episode 148 Reward: 214.0 Average over 100 episodes: 63.17\n",
            "Mean Value Loss: 10.053494453430176, Mean Policy Loss: 0.003509307513013482\n",
            "Episode 149 Reward: 81.0 Average over 100 episodes: 63.74\n",
            "Mean Value Loss: 30.391939163208008, Mean Policy Loss: -0.14100420475006104\n",
            "Episode 150 Reward: 145.0 Average over 100 episodes: 65.04\n",
            "Mean Value Loss: 12.758318901062012, Mean Policy Loss: 0.02351161278784275\n",
            "Episode 151 Reward: 178.0 Average over 100 episodes: 66.58\n",
            "Mean Value Loss: 8.619915962219238, Mean Policy Loss: 0.055080462247133255\n",
            "Episode 152 Reward: 60.0 Average over 100 episodes: 66.98\n",
            "Mean Value Loss: 30.182886123657227, Mean Policy Loss: 0.05862632766366005\n",
            "Episode 153 Reward: 205.0 Average over 100 episodes: 68.92\n",
            "Mean Value Loss: 3.864575147628784, Mean Policy Loss: 0.06062445789575577\n",
            "Episode 154 Reward: 163.0 Average over 100 episodes: 69.97\n",
            "Mean Value Loss: 4.860440731048584, Mean Policy Loss: 0.06957690417766571\n",
            "Episode 155 Reward: 134.0 Average over 100 episodes: 71.2\n",
            "Mean Value Loss: 4.6058526039123535, Mean Policy Loss: 0.023143457248806953\n",
            "Episode 156 Reward: 26.0 Average over 100 episodes: 71.2\n",
            "Mean Value Loss: 107.09627532958984, Mean Policy Loss: -0.13868843019008636\n",
            "Episode 157 Reward: 121.0 Average over 100 episodes: 72.28\n",
            "Mean Value Loss: 10.933958053588867, Mean Policy Loss: -0.02204027958214283\n",
            "Episode 158 Reward: 112.0 Average over 100 episodes: 73.19\n",
            "Mean Value Loss: 50.04018020629883, Mean Policy Loss: -0.2403036504983902\n",
            "Episode 159 Reward: 102.0 Average over 100 episodes: 74.01\n",
            "Mean Value Loss: 17.88236427307129, Mean Policy Loss: 0.07385462522506714\n",
            "Episode 160 Reward: 157.0 Average over 100 episodes: 75.48\n",
            "Mean Value Loss: 11.435502052307129, Mean Policy Loss: -0.05389070138335228\n",
            "Episode 161 Reward: 318.0 Average over 100 episodes: 78.49\n",
            "Mean Value Loss: 5.181277275085449, Mean Policy Loss: 0.014471178874373436\n",
            "Episode 162 Reward: 241.0 Average over 100 episodes: 80.24\n",
            "Mean Value Loss: 7.2607808113098145, Mean Policy Loss: 0.007477917708456516\n",
            "Episode 163 Reward: 137.0 Average over 100 episodes: 81.4\n",
            "Mean Value Loss: 4.06178617477417, Mean Policy Loss: -0.039231445640325546\n",
            "Episode 164 Reward: 157.0 Average over 100 episodes: 82.69\n",
            "Mean Value Loss: 2.090424060821533, Mean Policy Loss: -0.047857556492090225\n",
            "Episode 165 Reward: 100.0 Average over 100 episodes: 83.47\n",
            "Mean Value Loss: 0.4543516933917999, Mean Policy Loss: -0.06365861743688583\n",
            "Episode 166 Reward: 130.0 Average over 100 episodes: 84.48\n",
            "Mean Value Loss: 1.0318150520324707, Mean Policy Loss: -0.003388739190995693\n",
            "Episode 167 Reward: 168.0 Average over 100 episodes: 85.98\n",
            "Mean Value Loss: 5.474717140197754, Mean Policy Loss: -0.005298567470163107\n",
            "Episode 168 Reward: 118.0 Average over 100 episodes: 86.99\n",
            "Mean Value Loss: 1.968658685684204, Mean Policy Loss: -0.07358995079994202\n",
            "Episode 169 Reward: 179.0 Average over 100 episodes: 88.53\n",
            "Mean Value Loss: 0.4287113547325134, Mean Policy Loss: -0.03583604469895363\n",
            "Episode 170 Reward: 171.0 Average over 100 episodes: 89.71\n",
            "Mean Value Loss: 1.7987451553344727, Mean Policy Loss: -0.04647785797715187\n",
            "Episode 171 Reward: 180.0 Average over 100 episodes: 91.37\n",
            "Mean Value Loss: 2.311039686203003, Mean Policy Loss: -0.025897692888975143\n",
            "Episode 172 Reward: 388.0 Average over 100 episodes: 95.11\n",
            "Mean Value Loss: 4.877312183380127, Mean Policy Loss: 3.9859685784904286e-05\n",
            "Episode 173 Reward: 457.0 Average over 100 episodes: 99.55\n",
            "Mean Value Loss: 12.376141548156738, Mean Policy Loss: -0.003101118840277195\n",
            "Episode 174 Reward: 100.0 Average over 100 episodes: 100.06\n",
            "Mean Value Loss: 96.4123306274414, Mean Policy Loss: -0.28957661986351013\n",
            "Episode 175 Reward: 49.0 Average over 100 episodes: 100.34\n",
            "Mean Value Loss: 152.07838439941406, Mean Policy Loss: -2.16694974899292\n",
            "Episode 176 Reward: 247.0 Average over 100 episodes: 102.49\n",
            "Mean Value Loss: 57.38982391357422, Mean Policy Loss: 0.059862829744815826\n",
            "Episode 177 Reward: 126.0 Average over 100 episodes: 103.58\n",
            "Mean Value Loss: 46.75386047363281, Mean Policy Loss: 0.10501738637685776\n",
            "Episode 178 Reward: 69.0 Average over 100 episodes: 103.63\n",
            "Mean Value Loss: 68.72486877441406, Mean Policy Loss: 0.28480467200279236\n",
            "Episode 179 Reward: 28.0 Average over 100 episodes: 103.5\n",
            "Mean Value Loss: 140.4761505126953, Mean Policy Loss: 0.32960304617881775\n",
            "Episode 180 Reward: 31.0 Average over 100 episodes: 103.35\n",
            "Mean Value Loss: 109.91163635253906, Mean Policy Loss: -0.0035857539623975754\n",
            "Episode 181 Reward: 114.0 Average over 100 episodes: 104.29\n",
            "Mean Value Loss: 41.02105712890625, Mean Policy Loss: -0.006390605121850967\n",
            "Episode 182 Reward: 27.0 Average over 100 episodes: 103.61\n",
            "Mean Value Loss: 101.52345275878906, Mean Policy Loss: 0.02679542265832424\n",
            "Episode 183 Reward: 40.0 Average over 100 episodes: 103.24\n",
            "Mean Value Loss: 52.6296272277832, Mean Policy Loss: -0.09436647593975067\n",
            "Episode 184 Reward: 39.0 Average over 100 episodes: 103.34\n",
            "Mean Value Loss: 51.84937286376953, Mean Policy Loss: -0.05599753186106682\n",
            "Episode 185 Reward: 30.0 Average over 100 episodes: 102.52\n",
            "Mean Value Loss: 60.28849411010742, Mean Policy Loss: -0.3693813979625702\n",
            "Episode 186 Reward: 42.0 Average over 100 episodes: 102.14\n",
            "Mean Value Loss: 33.175418853759766, Mean Policy Loss: -0.060225170105695724\n",
            "Episode 187 Reward: 31.0 Average over 100 episodes: 100.79\n",
            "Mean Value Loss: 48.70624923706055, Mean Policy Loss: -0.19540639221668243\n",
            "Episode 188 Reward: 34.0 Average over 100 episodes: 100.45\n",
            "Mean Value Loss: 35.00775146484375, Mean Policy Loss: -0.2360655814409256\n",
            "Episode 189 Reward: 31.0 Average over 100 episodes: 100.29\n",
            "Mean Value Loss: 34.03886413574219, Mean Policy Loss: -0.026678631082177162\n",
            "Episode 190 Reward: 21.0 Average over 100 episodes: 99.94\n",
            "Mean Value Loss: 58.314353942871094, Mean Policy Loss: -0.12342748045921326\n",
            "Episode 191 Reward: 32.0 Average over 100 episodes: 99.04\n",
            "Mean Value Loss: 28.070859909057617, Mean Policy Loss: -0.05070039629936218\n",
            "Episode 192 Reward: 25.0 Average over 100 episodes: 98.36\n",
            "Mean Value Loss: 28.87515640258789, Mean Policy Loss: -0.05763031169772148\n",
            "Episode 193 Reward: 98.0 Average over 100 episodes: 97.94\n",
            "Mean Value Loss: 14.730764389038086, Mean Policy Loss: 0.2747824490070343\n",
            "Episode 194 Reward: 98.0 Average over 100 episodes: 98.48\n",
            "Mean Value Loss: 15.885083198547363, Mean Policy Loss: -0.02281648851931095\n",
            "Episode 195 Reward: 128.0 Average over 100 episodes: 99.08\n",
            "Mean Value Loss: 22.843332290649414, Mean Policy Loss: 0.11172731220722198\n",
            "Episode 196 Reward: 126.0 Average over 100 episodes: 99.9\n",
            "Mean Value Loss: 17.541967391967773, Mean Policy Loss: -0.018298326060175896\n",
            "Episode 197 Reward: 120.0 Average over 100 episodes: 100.83\n",
            "Mean Value Loss: 15.83388614654541, Mean Policy Loss: 0.06993743032217026\n",
            "Episode 198 Reward: 238.0 Average over 100 episodes: 102.97\n",
            "Mean Value Loss: 9.969046592712402, Mean Policy Loss: 0.042709968984127045\n",
            "Episode 199 Reward: 225.0 Average over 100 episodes: 104.1\n",
            "Mean Value Loss: 14.317216873168945, Mean Policy Loss: 0.04415656626224518\n",
            "Episode 200 Reward: 194.0 Average over 100 episodes: 104.91\n",
            "Mean Value Loss: 15.569886207580566, Mean Policy Loss: 0.02758900821208954\n",
            "Episode 201 Reward: 274.0 Average over 100 episodes: 106.64\n",
            "Mean Value Loss: 12.306963920593262, Mean Policy Loss: 0.007762709632515907\n",
            "Episode 202 Reward: 164.0 Average over 100 episodes: 107.62\n",
            "Mean Value Loss: 26.862966537475586, Mean Policy Loss: -0.022737665101885796\n",
            "Episode 203 Reward: 175.0 Average over 100 episodes: 108.97\n",
            "Mean Value Loss: 10.074207305908203, Mean Policy Loss: -0.006419827695935965\n",
            "Episode 204 Reward: 124.0 Average over 100 episodes: 109.91\n",
            "Mean Value Loss: 3.1457154750823975, Mean Policy Loss: 0.006527348887175322\n",
            "Episode 205 Reward: 171.0 Average over 100 episodes: 111.48\n",
            "Mean Value Loss: 6.115952491760254, Mean Policy Loss: -0.1195235475897789\n",
            "Episode 206 Reward: 50.0 Average over 100 episodes: 111.53\n",
            "Mean Value Loss: 53.599849700927734, Mean Policy Loss: -0.24876682460308075\n",
            "Episode 207 Reward: 83.0 Average over 100 episodes: 111.37\n",
            "Mean Value Loss: 8.412894248962402, Mean Policy Loss: -0.08014386892318726\n",
            "Episode 208 Reward: 136.0 Average over 100 episodes: 112.18\n",
            "Mean Value Loss: 3.137357711791992, Mean Policy Loss: -0.017838934436440468\n",
            "Episode 209 Reward: 124.0 Average over 100 episodes: 112.6\n",
            "Mean Value Loss: 0.8449854254722595, Mean Policy Loss: -0.05433056131005287\n",
            "Episode 210 Reward: 165.0 Average over 100 episodes: 113.66\n",
            "Mean Value Loss: 0.7785094976425171, Mean Policy Loss: -0.023543545976281166\n",
            "Episode 211 Reward: 165.0 Average over 100 episodes: 114.89\n",
            "Mean Value Loss: 4.765775680541992, Mean Policy Loss: -0.008153590373694897\n",
            "Episode 212 Reward: 133.0 Average over 100 episodes: 115.38\n",
            "Mean Value Loss: 0.8450433611869812, Mean Policy Loss: -0.10320266336202621\n",
            "Episode 213 Reward: 224.0 Average over 100 episodes: 117.33\n",
            "Mean Value Loss: 0.7177721261978149, Mean Policy Loss: -0.03780168667435646\n",
            "Episode 214 Reward: 247.0 Average over 100 episodes: 119.32\n",
            "Mean Value Loss: 0.6826310157775879, Mean Policy Loss: -0.03070198744535446\n",
            "Episode 215 Reward: 179.0 Average over 100 episodes: 120.82\n",
            "Mean Value Loss: 0.32817307114601135, Mean Policy Loss: -0.015410910360515118\n",
            "Episode 216 Reward: 187.0 Average over 100 episodes: 122.46\n",
            "Mean Value Loss: 5.540012836456299, Mean Policy Loss: -0.04041476547718048\n",
            "Episode 217 Reward: 189.0 Average over 100 episodes: 123.47\n",
            "Mean Value Loss: 3.9216697216033936, Mean Policy Loss: -0.018129514530301094\n",
            "Episode 218 Reward: 151.0 Average over 100 episodes: 124.36\n",
            "Mean Value Loss: 0.48330339789390564, Mean Policy Loss: -0.05764738842844963\n",
            "Episode 219 Reward: 139.0 Average over 100 episodes: 124.61\n",
            "Mean Value Loss: 0.34413212537765503, Mean Policy Loss: -0.09517023712396622\n",
            "Episode 220 Reward: 300.0 Average over 100 episodes: 126.83\n",
            "Mean Value Loss: 0.32985469698905945, Mean Policy Loss: -0.005195835139602423\n",
            "Episode 221 Reward: 162.0 Average over 100 episodes: 127.37\n",
            "Mean Value Loss: 0.26126810908317566, Mean Policy Loss: -0.06639483571052551\n",
            "Episode 222 Reward: 198.0 Average over 100 episodes: 128.92\n",
            "Mean Value Loss: 0.2509346902370453, Mean Policy Loss: -0.01680143177509308\n",
            "Episode 223 Reward: 173.0 Average over 100 episodes: 130.22\n",
            "Mean Value Loss: 0.6729523539543152, Mean Policy Loss: -0.0833636075258255\n",
            "Episode 224 Reward: 259.0 Average over 100 episodes: 131.53\n",
            "Mean Value Loss: 4.557168006896973, Mean Policy Loss: -0.0367872454226017\n",
            "Episode 225 Reward: 209.0 Average over 100 episodes: 132.66\n",
            "Mean Value Loss: 2.8312056064605713, Mean Policy Loss: -0.020564569160342216\n",
            "Episode 226 Reward: 197.0 Average over 100 episodes: 133.74\n",
            "Mean Value Loss: 1.9143561124801636, Mean Policy Loss: -0.008952248841524124\n",
            "Episode 227 Reward: 195.0 Average over 100 episodes: 135.05\n",
            "Mean Value Loss: 1.223699927330017, Mean Policy Loss: -0.02791929990053177\n",
            "Episode 228 Reward: 500.0 Average over 100 episodes: 139.36\n",
            "Mean Value Loss: 12.330062866210938, Mean Policy Loss: 0.012028196826577187\n",
            "Episode 229 Reward: 194.0 Average over 100 episodes: 140.9\n",
            "Mean Value Loss: 5.920586109161377, Mean Policy Loss: -0.01726672239601612\n",
            "Episode 230 Reward: 203.0 Average over 100 episodes: 142.45\n",
            "Mean Value Loss: 0.394405722618103, Mean Policy Loss: -0.04168236628174782\n",
            "Episode 231 Reward: 362.0 Average over 100 episodes: 145.35\n",
            "Mean Value Loss: 0.6472223401069641, Mean Policy Loss: -0.008288664743304253\n",
            "Episode 232 Reward: 314.0 Average over 100 episodes: 147.71\n",
            "Mean Value Loss: 0.22364212572574615, Mean Policy Loss: -0.0090617211535573\n",
            "Episode 233 Reward: 386.0 Average over 100 episodes: 150.6\n",
            "Mean Value Loss: 1.2808810472488403, Mean Policy Loss: -0.017777280882000923\n",
            "Episode 234 Reward: 492.0 Average over 100 episodes: 154.45\n",
            "Mean Value Loss: 36.64582443237305, Mean Policy Loss: -0.0028785872273147106\n",
            "Episode 235 Reward: 139.0 Average over 100 episodes: 154.63\n",
            "Mean Value Loss: 71.45551300048828, Mean Policy Loss: 0.054306503385305405\n",
            "Episode 236 Reward: 44.0 Average over 100 episodes: 154.71\n",
            "Mean Value Loss: 123.58643341064453, Mean Policy Loss: -0.11631833761930466\n",
            "Episode 237 Reward: 90.0 Average over 100 episodes: 154.5\n",
            "Mean Value Loss: 64.27337646484375, Mean Policy Loss: 0.0036118587013334036\n",
            "Episode 238 Reward: 109.0 Average over 100 episodes: 154.89\n",
            "Mean Value Loss: 43.297725677490234, Mean Policy Loss: -0.056083451956510544\n",
            "Episode 239 Reward: 110.0 Average over 100 episodes: 155.3\n",
            "Mean Value Loss: 33.522281646728516, Mean Policy Loss: 0.002792034298181534\n",
            "Episode 240 Reward: 119.0 Average over 100 episodes: 154.77\n",
            "Mean Value Loss: 34.066585540771484, Mean Policy Loss: -0.13110226392745972\n",
            "Episode 241 Reward: 246.0 Average over 100 episodes: 155.84\n",
            "Mean Value Loss: 12.268231391906738, Mean Policy Loss: 0.045891907066106796\n",
            "Episode 242 Reward: 247.0 Average over 100 episodes: 157.58\n",
            "Mean Value Loss: 7.109090328216553, Mean Policy Loss: 0.018621966242790222\n",
            "Episode 243 Reward: 163.0 Average over 100 episodes: 157.83\n",
            "Mean Value Loss: 13.381558418273926, Mean Policy Loss: 0.04775797203183174\n",
            "Episode 244 Reward: 179.0 Average over 100 episodes: 158.63\n",
            "Mean Value Loss: 6.731141090393066, Mean Policy Loss: 0.01808469370007515\n",
            "Episode 245 Reward: 159.0 Average over 100 episodes: 159.06\n",
            "Mean Value Loss: 6.324837684631348, Mean Policy Loss: -0.005229494068771601\n",
            "Episode 246 Reward: 146.0 Average over 100 episodes: 158.63\n",
            "Mean Value Loss: 15.728306770324707, Mean Policy Loss: 0.02672365866601467\n",
            "Episode 247 Reward: 133.0 Average over 100 episodes: 158.93\n",
            "Mean Value Loss: 12.465907096862793, Mean Policy Loss: -0.008121579885482788\n",
            "Episode 248 Reward: 213.0 Average over 100 episodes: 158.92\n",
            "Mean Value Loss: 2.0218751430511475, Mean Policy Loss: 0.03201178088784218\n",
            "Episode 249 Reward: 144.0 Average over 100 episodes: 159.55\n",
            "Mean Value Loss: 9.20187759399414, Mean Policy Loss: 0.01126506645232439\n",
            "Episode 250 Reward: 406.0 Average over 100 episodes: 162.16\n",
            "Mean Value Loss: 1.4435988664627075, Mean Policy Loss: 0.04048352688550949\n",
            "Episode 251 Reward: 500.0 Average over 100 episodes: 165.38\n",
            "Mean Value Loss: 17.937747955322266, Mean Policy Loss: 0.007774980738759041\n",
            "Episode 252 Reward: 166.0 Average over 100 episodes: 166.44\n",
            "Mean Value Loss: 32.9102668762207, Mean Policy Loss: 0.03590527921915054\n",
            "Episode 253 Reward: 162.0 Average over 100 episodes: 166.01\n",
            "Mean Value Loss: 5.970034122467041, Mean Policy Loss: -0.03205065801739693\n",
            "Episode 254 Reward: 173.0 Average over 100 episodes: 166.11\n",
            "Mean Value Loss: 1.941264271736145, Mean Policy Loss: 0.013236195780336857\n",
            "Episode 255 Reward: 261.0 Average over 100 episodes: 167.38\n",
            "Mean Value Loss: 7.122796535491943, Mean Policy Loss: 0.033650245517492294\n",
            "Episode 256 Reward: 176.0 Average over 100 episodes: 168.88\n",
            "Mean Value Loss: 2.365107536315918, Mean Policy Loss: 0.007134173531085253\n",
            "Episode 257 Reward: 135.0 Average over 100 episodes: 169.02\n",
            "Mean Value Loss: 7.957378387451172, Mean Policy Loss: 0.010188977234065533\n",
            "Episode 258 Reward: 168.0 Average over 100 episodes: 169.58\n",
            "Mean Value Loss: 0.31611379981040955, Mean Policy Loss: 0.016039930284023285\n",
            "Episode 259 Reward: 205.0 Average over 100 episodes: 170.61\n",
            "Mean Value Loss: 1.116296648979187, Mean Policy Loss: 0.03068041056394577\n",
            "Episode 260 Reward: 213.0 Average over 100 episodes: 171.17\n",
            "Mean Value Loss: 0.3664848506450653, Mean Policy Loss: 0.014586043544113636\n",
            "Episode 261 Reward: 248.0 Average over 100 episodes: 170.47\n",
            "Mean Value Loss: 0.25778907537460327, Mean Policy Loss: 0.0027994292322546244\n",
            "Episode 262 Reward: 209.0 Average over 100 episodes: 170.15\n",
            "Mean Value Loss: 0.08132178336381912, Mean Policy Loss: 0.023009300231933594\n",
            "Episode 263 Reward: 254.0 Average over 100 episodes: 171.32\n",
            "Mean Value Loss: 0.10526065528392792, Mean Policy Loss: 0.014498344622552395\n",
            "Episode 264 Reward: 344.0 Average over 100 episodes: 173.19\n",
            "Mean Value Loss: 0.17701475322246552, Mean Policy Loss: 0.008202576078474522\n",
            "Episode 265 Reward: 195.0 Average over 100 episodes: 174.14\n",
            "Mean Value Loss: 0.20810537040233612, Mean Policy Loss: 0.0007323393365368247\n",
            "Episode 266 Reward: 272.0 Average over 100 episodes: 175.56\n",
            "Mean Value Loss: 0.10897871851921082, Mean Policy Loss: 0.018854983150959015\n",
            "Episode 267 Reward: 291.0 Average over 100 episodes: 176.79\n",
            "Mean Value Loss: 0.27715766429901123, Mean Policy Loss: 0.008982395753264427\n",
            "Episode 268 Reward: 290.0 Average over 100 episodes: 178.51\n",
            "Mean Value Loss: 19.868303298950195, Mean Policy Loss: -0.002458626637235284\n",
            "Episode 269 Reward: 434.0 Average over 100 episodes: 181.06\n",
            "Mean Value Loss: 0.9795278906822205, Mean Policy Loss: 0.010324140079319477\n",
            "Episode 270 Reward: 165.0 Average over 100 episodes: 181.0\n",
            "Mean Value Loss: 0.9199475049972534, Mean Policy Loss: 0.017808634787797928\n",
            "Episode 271 Reward: 213.0 Average over 100 episodes: 181.33\n",
            "Mean Value Loss: 1.1801223754882812, Mean Policy Loss: 0.0007317553390748799\n",
            "Episode 272 Reward: 488.0 Average over 100 episodes: 182.33\n",
            "Mean Value Loss: 5.481311321258545, Mean Policy Loss: 0.016095910221338272\n",
            "Episode 273 Reward: 217.0 Average over 100 episodes: 179.93\n",
            "Mean Value Loss: 0.5662665367126465, Mean Policy Loss: -0.0010828966042026877\n",
            "Episode 274 Reward: 233.0 Average over 100 episodes: 181.26\n",
            "Mean Value Loss: 0.2625153064727783, Mean Policy Loss: -0.00842193327844143\n",
            "Episode 275 Reward: 181.0 Average over 100 episodes: 182.58\n",
            "Mean Value Loss: 0.444607675075531, Mean Policy Loss: -0.01082121767103672\n",
            "Episode 276 Reward: 205.0 Average over 100 episodes: 182.16\n",
            "Mean Value Loss: 0.13622832298278809, Mean Policy Loss: -0.010058935731649399\n",
            "Episode 277 Reward: 273.0 Average over 100 episodes: 183.63\n",
            "Mean Value Loss: 0.38194963335990906, Mean Policy Loss: 0.006069609895348549\n",
            "Episode 278 Reward: 221.0 Average over 100 episodes: 185.15\n",
            "Mean Value Loss: 0.0964958593249321, Mean Policy Loss: 0.010137085802853107\n",
            "Episode 279 Reward: 248.0 Average over 100 episodes: 187.35\n",
            "Mean Value Loss: 0.05169132724404335, Mean Policy Loss: 0.01021631434559822\n",
            "Episode 280 Reward: 308.0 Average over 100 episodes: 190.12\n",
            "Mean Value Loss: 0.08570817857980728, Mean Policy Loss: -0.0028799758292734623\n",
            "Episode 281 Reward: 288.0 Average over 100 episodes: 191.86\n",
            "Mean Value Loss: 1.475098967552185, Mean Policy Loss: -0.005841133184731007\n",
            "Episode 282 Reward: 262.0 Average over 100 episodes: 194.21\n",
            "Mean Value Loss: 0.13842298090457916, Mean Policy Loss: -0.022301221266388893\n",
            "Episode 283 Reward: 219.0 Average over 100 episodes: 196.0\n",
            "Mean Value Loss: 0.8146385550498962, Mean Policy Loss: 0.018662167713046074\n",
            "Episode 284 Reward: 212.0 Average over 100 episodes: 197.73\n",
            "Mean Value Loss: 0.08475766330957413, Mean Policy Loss: -0.011967460624873638\n",
            "Episode 285 Reward: 261.0 Average over 100 episodes: 200.04\n",
            "Mean Value Loss: 1.5639495849609375, Mean Policy Loss: -0.0016420764150097966\n",
            "Episode 286 Reward: 344.0 Average over 100 episodes: 203.06\n",
            "Mean Value Loss: 0.2422792762517929, Mean Policy Loss: 0.00502110505476594\n",
            "Episode 287 Reward: 359.0 Average over 100 episodes: 206.34\n",
            "Mean Value Loss: 2.199130058288574, Mean Policy Loss: -0.01661386713385582\n",
            "Episode 288 Reward: 417.0 Average over 100 episodes: 210.17\n",
            "Mean Value Loss: 0.7944883108139038, Mean Policy Loss: -0.03722783923149109\n",
            "Episode 289 Reward: 63.0 Average over 100 episodes: 210.49\n",
            "Mean Value Loss: 116.05902862548828, Mean Policy Loss: -0.1575491726398468\n",
            "Episode 290 Reward: 196.0 Average over 100 episodes: 212.24\n",
            "Mean Value Loss: 6.718147277832031, Mean Policy Loss: 0.042375653982162476\n",
            "Episode 291 Reward: 174.0 Average over 100 episodes: 213.66\n",
            "Mean Value Loss: 0.22567042708396912, Mean Policy Loss: -0.040330782532691956\n",
            "Episode 292 Reward: 199.0 Average over 100 episodes: 215.4\n",
            "Mean Value Loss: 0.08635103702545166, Mean Policy Loss: 0.0009345103753730655\n",
            "Episode 293 Reward: 194.0 Average over 100 episodes: 216.36\n",
            "Mean Value Loss: 0.5484069585800171, Mean Policy Loss: -0.008987721987068653\n",
            "Episode 294 Reward: 231.0 Average over 100 episodes: 217.69\n",
            "Mean Value Loss: 0.43153831362724304, Mean Policy Loss: -0.005618543829768896\n",
            "Episode 295 Reward: 238.0 Average over 100 episodes: 218.79\n",
            "Mean Value Loss: 0.19237656891345978, Mean Policy Loss: -0.029825404286384583\n",
            "Episode 296 Reward: 373.0 Average over 100 episodes: 221.26\n",
            "Mean Value Loss: 0.9853518605232239, Mean Policy Loss: -0.008545665070414543\n",
            "Episode 297 Reward: 246.0 Average over 100 episodes: 222.52\n",
            "Mean Value Loss: 1.1616051197052002, Mean Policy Loss: -0.009585756808519363\n",
            "Episode 298 Reward: 263.0 Average over 100 episodes: 222.77\n",
            "Mean Value Loss: 0.756307065486908, Mean Policy Loss: -0.013886399567127228\n",
            "Episode 299 Reward: 228.0 Average over 100 episodes: 222.8\n",
            "Mean Value Loss: 0.14141644537448883, Mean Policy Loss: -0.0073175630532205105\n",
            "Episode 300 Reward: 308.0 Average over 100 episodes: 223.94\n",
            "Mean Value Loss: 0.6350463628768921, Mean Policy Loss: -0.022199727594852448\n",
            "Episode 301 Reward: 342.0 Average over 100 episodes: 224.62\n",
            "Mean Value Loss: 2.235704183578491, Mean Policy Loss: -0.01195253524929285\n",
            "Episode 302 Reward: 440.0 Average over 100 episodes: 227.38\n",
            "Mean Value Loss: 2.154989242553711, Mean Policy Loss: -0.016648612916469574\n",
            "Episode 303 Reward: 286.0 Average over 100 episodes: 228.49\n",
            "Mean Value Loss: 0.5995984077453613, Mean Policy Loss: -0.03468158096075058\n",
            "Episode 304 Reward: 373.0 Average over 100 episodes: 230.98\n",
            "Mean Value Loss: 1.6045141220092773, Mean Policy Loss: 0.004596618935465813\n",
            "Episode 305 Reward: 255.0 Average over 100 episodes: 231.82\n",
            "Mean Value Loss: 0.7742964029312134, Mean Policy Loss: -0.02503783069550991\n",
            "Episode 306 Reward: 234.0 Average over 100 episodes: 233.66\n",
            "Mean Value Loss: 0.42870041728019714, Mean Policy Loss: -0.01594538427889347\n",
            "Episode 307 Reward: 260.0 Average over 100 episodes: 235.43\n",
            "Mean Value Loss: 1.0414619445800781, Mean Policy Loss: -0.02157001942396164\n",
            "Episode 308 Reward: 288.0 Average over 100 episodes: 236.95\n",
            "Mean Value Loss: 1.6193232536315918, Mean Policy Loss: -0.015915438532829285\n",
            "Episode 309 Reward: 387.0 Average over 100 episodes: 239.58\n",
            "Mean Value Loss: 2.5975191593170166, Mean Policy Loss: -0.008330258540809155\n",
            "Episode 310 Reward: 321.0 Average over 100 episodes: 241.14\n",
            "Mean Value Loss: 1.4292646646499634, Mean Policy Loss: -0.025754103437066078\n",
            "Episode 311 Reward: 332.0 Average over 100 episodes: 242.81\n",
            "Mean Value Loss: 2.7212882041931152, Mean Policy Loss: -0.018657982349395752\n",
            "Episode 312 Reward: 435.0 Average over 100 episodes: 245.83\n",
            "Mean Value Loss: 3.026404857635498, Mean Policy Loss: -0.008394214324653149\n",
            "Episode 313 Reward: 458.0 Average over 100 episodes: 248.17\n",
            "Mean Value Loss: 4.40708589553833, Mean Policy Loss: -0.007827703841030598\n",
            "Episode 314 Reward: 500.0 Average over 100 episodes: 250.7\n",
            "Mean Value Loss: 8.842229843139648, Mean Policy Loss: -0.031127752736210823\n",
            "Episode 315 Reward: 423.0 Average over 100 episodes: 253.14\n",
            "Mean Value Loss: 22.114797592163086, Mean Policy Loss: -0.0069839078933000565\n",
            "Episode 316 Reward: 500.0 Average over 100 episodes: 256.27\n",
            "Mean Value Loss: 14.189203262329102, Mean Policy Loss: -0.006608238909393549\n",
            "Episode 317 Reward: 402.0 Average over 100 episodes: 258.4\n",
            "Mean Value Loss: 17.341604232788086, Mean Policy Loss: 0.018428562209010124\n",
            "Episode 318 Reward: 500.0 Average over 100 episodes: 261.89\n",
            "Mean Value Loss: 11.266755104064941, Mean Policy Loss: -0.000909596448764205\n",
            "Episode 319 Reward: 500.0 Average over 100 episodes: 265.5\n",
            "Mean Value Loss: 9.541170120239258, Mean Policy Loss: -0.024409424513578415\n",
            "Episode 320 Reward: 500.0 Average over 100 episodes: 267.5\n",
            "Mean Value Loss: 3.483145236968994, Mean Policy Loss: -0.008245049975812435\n",
            "Episode 321 Reward: 454.0 Average over 100 episodes: 270.42\n",
            "Mean Value Loss: 3.450679302215576, Mean Policy Loss: -0.025000471621751785\n",
            "Episode 322 Reward: 500.0 Average over 100 episodes: 273.44\n",
            "Mean Value Loss: 4.490891456604004, Mean Policy Loss: -0.023978959769010544\n",
            "Episode 323 Reward: 500.0 Average over 100 episodes: 276.71\n",
            "Mean Value Loss: 11.494246482849121, Mean Policy Loss: -0.01688421331346035\n",
            "Episode 324 Reward: 500.0 Average over 100 episodes: 279.12\n",
            "Mean Value Loss: 14.014373779296875, Mean Policy Loss: -0.011652841232717037\n",
            "Episode 325 Reward: 500.0 Average over 100 episodes: 282.03\n",
            "Mean Value Loss: 12.188638687133789, Mean Policy Loss: -0.012225983664393425\n",
            "Episode 326 Reward: 500.0 Average over 100 episodes: 285.06\n",
            "Mean Value Loss: 15.35196304321289, Mean Policy Loss: -0.02029588259756565\n",
            "Episode 327 Reward: 500.0 Average over 100 episodes: 288.11\n",
            "Mean Value Loss: 17.35049819946289, Mean Policy Loss: 0.006915798410773277\n",
            "Episode 328 Reward: 500.0 Average over 100 episodes: 288.11\n",
            "Mean Value Loss: 15.879409790039062, Mean Policy Loss: 0.010341448709368706\n",
            "Episode 329 Reward: 500.0 Average over 100 episodes: 291.17\n",
            "Mean Value Loss: 15.79244613647461, Mean Policy Loss: -0.014080378226935863\n",
            "Episode 330 Reward: 500.0 Average over 100 episodes: 294.14\n",
            "Mean Value Loss: 14.047683715820312, Mean Policy Loss: 0.004180047195404768\n",
            "Episode 331 Reward: 500.0 Average over 100 episodes: 295.52\n",
            "Mean Value Loss: 16.116107940673828, Mean Policy Loss: -0.010403540916740894\n",
            "Episode 332 Reward: 500.0 Average over 100 episodes: 297.38\n",
            "Mean Value Loss: 12.203817367553711, Mean Policy Loss: -0.0194924958050251\n",
            "Episode 333 Reward: 500.0 Average over 100 episodes: 298.52\n",
            "Mean Value Loss: 13.078283309936523, Mean Policy Loss: -0.012866491451859474\n",
            "Episode 334 Reward: 500.0 Average over 100 episodes: 298.6\n",
            "Mean Value Loss: 8.520638465881348, Mean Policy Loss: 0.002194428350776434\n",
            "Episode 335 Reward: 500.0 Average over 100 episodes: 302.21\n",
            "Mean Value Loss: 9.41557502746582, Mean Policy Loss: -0.0052553401328623295\n",
            "Episode 336 Reward: 500.0 Average over 100 episodes: 306.77\n",
            "Mean Value Loss: 10.698959350585938, Mean Policy Loss: -0.0032078679651021957\n",
            "Episode 337 Reward: 500.0 Average over 100 episodes: 310.87\n",
            "Mean Value Loss: 18.35830307006836, Mean Policy Loss: -0.02089029736816883\n",
            "Episode 338 Reward: 500.0 Average over 100 episodes: 314.78\n",
            "Mean Value Loss: 14.247913360595703, Mean Policy Loss: -0.009844259358942509\n",
            "Episode 339 Reward: 500.0 Average over 100 episodes: 318.68\n",
            "Mean Value Loss: 10.650825500488281, Mean Policy Loss: -0.015336169861257076\n",
            "Episode 340 Reward: 500.0 Average over 100 episodes: 322.49\n",
            "Mean Value Loss: 11.546348571777344, Mean Policy Loss: -0.004872159566730261\n",
            "Episode 341 Reward: 500.0 Average over 100 episodes: 325.03\n",
            "Mean Value Loss: 8.49337387084961, Mean Policy Loss: 0.007081815041601658\n",
            "Episode 342 Reward: 500.0 Average over 100 episodes: 327.56\n",
            "Mean Value Loss: 15.623571395874023, Mean Policy Loss: -0.013158060610294342\n",
            "Episode 343 Reward: 500.0 Average over 100 episodes: 330.93\n",
            "Mean Value Loss: 12.758894920349121, Mean Policy Loss: -0.014902984723448753\n",
            "Episode 344 Reward: 500.0 Average over 100 episodes: 334.14\n",
            "Mean Value Loss: 13.69091796875, Mean Policy Loss: -0.02448609657585621\n",
            "Episode 345 Reward: 500.0 Average over 100 episodes: 337.55\n",
            "Mean Value Loss: 14.042707443237305, Mean Policy Loss: -0.012273324653506279\n",
            "Episode 346 Reward: 500.0 Average over 100 episodes: 341.09\n",
            "Mean Value Loss: 9.957883834838867, Mean Policy Loss: 0.020877547562122345\n",
            "Episode 347 Reward: 500.0 Average over 100 episodes: 344.76\n",
            "Mean Value Loss: 13.67052936553955, Mean Policy Loss: -0.007832847535610199\n",
            "Episode 348 Reward: 500.0 Average over 100 episodes: 347.63\n",
            "Mean Value Loss: 16.756446838378906, Mean Policy Loss: -0.00683889165520668\n",
            "Episode 349 Reward: 500.0 Average over 100 episodes: 351.19\n",
            "Mean Value Loss: 13.495141983032227, Mean Policy Loss: -0.01512449886649847\n",
            "Episode 350 Reward: 500.0 Average over 100 episodes: 352.13\n",
            "Mean Value Loss: 13.495643615722656, Mean Policy Loss: -0.0048317741602659225\n",
            "Episode 351 Reward: 500.0 Average over 100 episodes: 352.13\n",
            "Mean Value Loss: 15.314970016479492, Mean Policy Loss: -0.011295737698674202\n",
            "Episode 352 Reward: 500.0 Average over 100 episodes: 355.47\n",
            "Mean Value Loss: 13.810450553894043, Mean Policy Loss: 0.003390917321667075\n",
            "Episode 353 Reward: 500.0 Average over 100 episodes: 358.85\n",
            "Mean Value Loss: 13.560507774353027, Mean Policy Loss: -0.003875385969877243\n",
            "Episode 354 Reward: 500.0 Average over 100 episodes: 362.12\n",
            "Mean Value Loss: 10.571545600891113, Mean Policy Loss: 0.0034419295843690634\n",
            "Episode 355 Reward: 500.0 Average over 100 episodes: 364.51\n",
            "Mean Value Loss: 9.000570297241211, Mean Policy Loss: -0.012260233983397484\n",
            "Episode 356 Reward: 500.0 Average over 100 episodes: 367.75\n",
            "Mean Value Loss: 14.196752548217773, Mean Policy Loss: -0.0060840449295938015\n",
            "Episode 357 Reward: 500.0 Average over 100 episodes: 371.4\n",
            "Mean Value Loss: 13.649252891540527, Mean Policy Loss: -0.015959307551383972\n",
            "Episode 358 Reward: 500.0 Average over 100 episodes: 374.72\n",
            "Mean Value Loss: 13.192520141601562, Mean Policy Loss: -0.014398221857845783\n",
            "Episode 359 Reward: 500.0 Average over 100 episodes: 377.67\n",
            "Mean Value Loss: 11.738628387451172, Mean Policy Loss: -0.02634972706437111\n",
            "Episode 360 Reward: 500.0 Average over 100 episodes: 380.54\n",
            "Mean Value Loss: 11.391157150268555, Mean Policy Loss: -0.02691611461341381\n",
            "Episode 361 Reward: 500.0 Average over 100 episodes: 383.06\n",
            "Mean Value Loss: 14.71676254272461, Mean Policy Loss: -0.027827206999063492\n",
            "Episode 362 Reward: 500.0 Average over 100 episodes: 385.97\n",
            "Mean Value Loss: 12.325759887695312, Mean Policy Loss: -0.004316582344472408\n",
            "Episode 363 Reward: 500.0 Average over 100 episodes: 388.43\n",
            "Mean Value Loss: 15.394074440002441, Mean Policy Loss: -0.02422749064862728\n",
            "Episode 364 Reward: 500.0 Average over 100 episodes: 389.99\n",
            "Mean Value Loss: 15.145040512084961, Mean Policy Loss: -0.02333667501807213\n",
            "Episode 365 Reward: 500.0 Average over 100 episodes: 393.04\n",
            "Mean Value Loss: 13.34366226196289, Mean Policy Loss: -0.011068916879594326\n",
            "Episode 366 Reward: 500.0 Average over 100 episodes: 395.32\n",
            "Mean Value Loss: 12.20988655090332, Mean Policy Loss: 0.008246786892414093\n",
            "Episode 367 Reward: 500.0 Average over 100 episodes: 397.41\n",
            "Mean Value Loss: 14.883552551269531, Mean Policy Loss: -0.012586715631186962\n",
            "Episode 368 Reward: 500.0 Average over 100 episodes: 399.51\n",
            "Mean Value Loss: 11.312941551208496, Mean Policy Loss: -0.03484337776899338\n",
            "Episode 369 Reward: 500.0 Average over 100 episodes: 400.17\n",
            "Mean Value Loss: 9.736641883850098, Mean Policy Loss: -0.0021457418333739042\n",
            "Episode 370 Reward: 500.0 Average over 100 episodes: 403.52\n",
            "Mean Value Loss: 11.782642364501953, Mean Policy Loss: -0.01933382824063301\n",
            "Episode 371 Reward: 500.0 Average over 100 episodes: 406.39\n",
            "Mean Value Loss: 14.118471145629883, Mean Policy Loss: -0.015442687086760998\n",
            "Episode 372 Reward: 500.0 Average over 100 episodes: 406.51\n",
            "Mean Value Loss: 15.522177696228027, Mean Policy Loss: -0.024372482672333717\n",
            "Episode 373 Reward: 500.0 Average over 100 episodes: 409.34\n",
            "Mean Value Loss: 16.02499008178711, Mean Policy Loss: -0.030196662992239\n",
            "Episode 374 Reward: 500.0 Average over 100 episodes: 412.01\n",
            "Mean Value Loss: 15.321149826049805, Mean Policy Loss: -0.017007704824209213\n",
            "Episode 375 Reward: 500.0 Average over 100 episodes: 415.2\n",
            "Mean Value Loss: 14.373050689697266, Mean Policy Loss: -0.006118697114288807\n",
            "Episode 376 Reward: 500.0 Average over 100 episodes: 418.15\n",
            "Mean Value Loss: 12.469812393188477, Mean Policy Loss: -0.019102569669485092\n",
            "Episode 377 Reward: 500.0 Average over 100 episodes: 420.42\n",
            "Mean Value Loss: 13.006352424621582, Mean Policy Loss: -0.011645132675766945\n",
            "Episode 378 Reward: 500.0 Average over 100 episodes: 423.21\n",
            "Mean Value Loss: 13.000091552734375, Mean Policy Loss: -0.03617185726761818\n",
            "Episode 379 Reward: 500.0 Average over 100 episodes: 425.73\n",
            "Mean Value Loss: 14.839686393737793, Mean Policy Loss: -0.01506126206368208\n",
            "Episode 380 Reward: 500.0 Average over 100 episodes: 427.65\n",
            "Mean Value Loss: 11.611303329467773, Mean Policy Loss: -0.025873204693198204\n",
            "Episode 381 Reward: 500.0 Average over 100 episodes: 429.77\n",
            "Mean Value Loss: 15.262652397155762, Mean Policy Loss: -0.0010702230501919985\n",
            "Episode 382 Reward: 500.0 Average over 100 episodes: 432.15\n",
            "Mean Value Loss: 15.601595878601074, Mean Policy Loss: -0.007813667878508568\n",
            "Episode 383 Reward: 500.0 Average over 100 episodes: 434.96\n",
            "Mean Value Loss: 15.677506446838379, Mean Policy Loss: -0.005884170066565275\n",
            "Episode 384 Reward: 500.0 Average over 100 episodes: 437.84\n",
            "Mean Value Loss: 15.175440788269043, Mean Policy Loss: -0.02981732413172722\n",
            "Episode 385 Reward: 500.0 Average over 100 episodes: 440.23\n",
            "Mean Value Loss: 14.966907501220703, Mean Policy Loss: -0.0036625780630856752\n",
            "Episode 386 Reward: 500.0 Average over 100 episodes: 441.79\n",
            "Mean Value Loss: 13.327604293823242, Mean Policy Loss: -0.006399770267307758\n",
            "Episode 387 Reward: 500.0 Average over 100 episodes: 443.2\n",
            "Mean Value Loss: 14.101035118103027, Mean Policy Loss: -0.011849146336317062\n",
            "Episode 388 Reward: 500.0 Average over 100 episodes: 444.03\n",
            "Mean Value Loss: 14.5194091796875, Mean Policy Loss: -0.012749932706356049\n",
            "Episode 389 Reward: 500.0 Average over 100 episodes: 448.4\n",
            "Mean Value Loss: 11.857073783874512, Mean Policy Loss: -0.0223299078643322\n",
            "Episode 390 Reward: 500.0 Average over 100 episodes: 451.44\n",
            "Mean Value Loss: 14.251558303833008, Mean Policy Loss: -0.011123544536530972\n",
            "Episode 391 Reward: 500.0 Average over 100 episodes: 454.7\n",
            "Mean Value Loss: 11.891683578491211, Mean Policy Loss: -0.013597534969449043\n",
            "Episode 392 Reward: 500.0 Average over 100 episodes: 457.71\n",
            "Mean Value Loss: 14.478606224060059, Mean Policy Loss: -0.016948966309428215\n",
            "Episode 393 Reward: 51.0 Average over 100 episodes: 456.28\n",
            "Mean Value Loss: 122.6683578491211, Mean Policy Loss: -0.29231446981430054\n",
            "Episode 394 Reward: 500.0 Average over 100 episodes: 458.97\n",
            "Mean Value Loss: 9.780425071716309, Mean Policy Loss: -0.01683543249964714\n",
            "Episode 395 Reward: 419.0 Average over 100 episodes: 460.78\n",
            "Mean Value Loss: 13.977598190307617, Mean Policy Loss: -0.0061865090392529964\n",
            "Episode 396 Reward: 500.0 Average over 100 episodes: 462.05\n",
            "Mean Value Loss: 10.735794067382812, Mean Policy Loss: 0.007867258973419666\n",
            "Episode 397 Reward: 500.0 Average over 100 episodes: 464.59\n",
            "Mean Value Loss: 11.283349990844727, Mean Policy Loss: -0.013858355581760406\n",
            "Episode 398 Reward: 500.0 Average over 100 episodes: 466.96\n",
            "Mean Value Loss: 8.75774097442627, Mean Policy Loss: 0.00039637781446799636\n",
            "Episode 399 Reward: 500.0 Average over 100 episodes: 469.68\n",
            "Mean Value Loss: 12.86543083190918, Mean Policy Loss: -0.004972271155565977\n",
            "Episode 400 Reward: 500.0 Average over 100 episodes: 471.6\n",
            "Mean Value Loss: 10.709479331970215, Mean Policy Loss: -0.025511205196380615\n",
            "Episode 401 Reward: 500.0 Average over 100 episodes: 473.18\n",
            "Mean Value Loss: 9.415220260620117, Mean Policy Loss: -0.010841608047485352\n",
            "Episode 402 Reward: 500.0 Average over 100 episodes: 473.78\n",
            "Mean Value Loss: 8.25849437713623, Mean Policy Loss: -0.004983620252460241\n",
            "Episode 403 Reward: 500.0 Average over 100 episodes: 475.92\n",
            "Mean Value Loss: 10.876218795776367, Mean Policy Loss: -0.022120211273431778\n",
            " Solved at episode: 403\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard \n",
        "%tensorboard --logdir \".logs/\"\n"
      ],
      "metadata": {
        "id": "MsvVAUThTCCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ePLDEFVObgud",
        "outputId": "d299c8b1-a00b-40c2-c37e-d0e6c5744d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6007 (pid 298), started 0:00:04 ago. (Use '!kill 298' to kill it.)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6007, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}